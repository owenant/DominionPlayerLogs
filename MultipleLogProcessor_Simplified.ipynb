{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "371cd34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzips and re-zips individual log files and processes each one by calling out to the single file player \n",
    "#log processor\n",
    "import logging\n",
    "import os\n",
    "import pdb\n",
    "import tarfile\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import shutil\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b57db2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set-directory of compressed files to process\n",
    "year_dir_name = '2012-all/'\n",
    "dir_name = 'DominionPlayerLogs/' +  year_dir_name\n",
    "output_dir = 'ProcessedLogs/' + year_dir_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efc0226f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of directories to loop through: 366\n"
     ]
    }
   ],
   "source": [
    "print(\"No of directories to loop through: \" + str(len(os.listdir(dir_name))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d983910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed directory 20120101.tar.bz2 in 10.967873966693878 minutes\n",
      "Number of directories processed 1\n",
      "Processed directory 20120102.tar.bz2 in 12.112566065788268 minutes\n",
      "Number of directories processed 2\n",
      "Processed directory 20120103.tar.bz2 in 10.988518667221069 minutes\n",
      "Number of directories processed 3\n",
      "Processed directory 20120104.tar.bz2 in 13.308150831858317 minutes\n",
      "Number of directories processed 4\n",
      "Processed directory 20120105.tar.bz2 in 13.222851884365081 minutes\n",
      "Number of directories processed 5\n",
      "Processed directory 20120106.tar.bz2 in 12.508947384357452 minutes\n",
      "Number of directories processed 6\n",
      "Processed directory 20120107.tar.bz2 in 12.1419912815094 minutes\n",
      "Number of directories processed 7\n",
      "Processed directory 20120108.tar.bz2 in 12.967961315313975 minutes\n",
      "Number of directories processed 8\n",
      "Processed directory 20120109.tar.bz2 in 13.867734066645305 minutes\n",
      "Number of directories processed 9\n",
      "Processed directory 20120110.tar.bz2 in 13.73196804523468 minutes\n",
      "Number of directories processed 10\n",
      "Processed directory 20120111.tar.bz2 in 13.552238182226818 minutes\n",
      "Number of directories processed 11\n",
      "Processed directory 20120112.tar.bz2 in 14.10044331550598 minutes\n",
      "Number of directories processed 12\n",
      "Processed directory 20120113.tar.bz2 in 16.91785573164622 minutes\n",
      "Number of directories processed 13\n",
      "Processed directory 20120114.tar.bz2 in 16.39672843615214 minutes\n",
      "Number of directories processed 14\n",
      "Processed directory 20120115.tar.bz2 in 17.559214051564535 minutes\n",
      "Number of directories processed 15\n",
      "Processed directory 20120116.tar.bz2 in 19.439024368921917 minutes\n",
      "Number of directories processed 16\n",
      "Processed directory 20120117.tar.bz2 in 16.225059962272645 minutes\n",
      "Number of directories processed 17\n",
      "Processed directory 20120118.tar.bz2 in 14.534820346037547 minutes\n",
      "Number of directories processed 18\n",
      "Processed directory 20120119.tar.bz2 in 14.24290817975998 minutes\n",
      "Number of directories processed 19\n",
      "Processed directory 20120120.tar.bz2 in 20.026286749045052 minutes\n",
      "Number of directories processed 20\n",
      "Processed directory 20120121.tar.bz2 in 18.113313563664754 minutes\n",
      "Number of directories processed 21\n",
      "Processed directory 20120122.tar.bz2 in 19.235973219076794 minutes\n",
      "Number of directories processed 22\n",
      "Processed directory 20120123.tar.bz2 in 18.765901664892834 minutes\n",
      "Number of directories processed 23\n",
      "Processed directory 20120124.tar.bz2 in 19.285786581039428 minutes\n",
      "Number of directories processed 24\n",
      "Processed directory 20120125.tar.bz2 in 18.541030100981395 minutes\n",
      "Number of directories processed 25\n",
      "Processed directory 20120126.tar.bz2 in 18.081481766700744 minutes\n",
      "Number of directories processed 26\n",
      "Processed directory 20120127.tar.bz2 in 17.89972701470057 minutes\n",
      "Number of directories processed 27\n",
      "Processed directory 20120128.tar.bz2 in 16.557612816492718 minutes\n",
      "Number of directories processed 28\n",
      "Processed directory 20120129.tar.bz2 in 18.14125286738078 minutes\n",
      "Number of directories processed 29\n",
      "Processed directory 20120130.tar.bz2 in 19.06360272963842 minutes\n",
      "Number of directories processed 30\n",
      "Processed directory 20120131.tar.bz2 in 50.52798048257828 minutes\n",
      "Number of directories processed 31\n",
      "Processed directory 20120201.tar.bz2 in 30.09766465028127 minutes\n",
      "Number of directories processed 32\n",
      "Processed directory 20120202.tar.bz2 in 30.980604914824166 minutes\n",
      "Number of directories processed 33\n",
      "Processed directory 20120203.tar.bz2 in 29.710460746288298 minutes\n",
      "Number of directories processed 34\n",
      "Processed directory 20120204.tar.bz2 in 60.00107365449269 minutes\n",
      "Number of directories processed 35\n",
      "Processed directory 20120205.tar.bz2 in 19.19430909951528 minutes\n",
      "Number of directories processed 36\n",
      "Processed directory 20120206.tar.bz2 in 299.43510445356367 minutes\n",
      "Number of directories processed 37\n",
      "Processed directory 20120207.tar.bz2 in 24.39952507019043 minutes\n",
      "Number of directories processed 38\n",
      "Processed directory 20120208.tar.bz2 in 17.39069793224335 minutes\n",
      "Number of directories processed 39\n",
      "Processed directory 20120209.tar.bz2 in 14.40501691500346 minutes\n",
      "Number of directories processed 40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m filename \u001b[38;5;241m=\u001b[39m extract_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m game_log\n\u001b[1;32m     33\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(filename, mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m soup \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhtml.parser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#convert html contents into a list of tabs, navigable strings etc\u001b[39;00m\n\u001b[1;32m     37\u001b[0m pre_tag \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/bs4/__init__.py:333\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39minitialize_soup(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/bs4/__init__.py:451\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# Convert the document to Unicode.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendData()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/bs4/builder/_htmlparser.py:399\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    397\u001b[0m parser\u001b[38;5;241m.\u001b[39msoup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoup\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m     parser\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTMLParseError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/html/parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03mas you want (may include '\\n').\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m+\u001b[39m data\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgoahead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/html/parser.py:170\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m startswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m, i):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m starttagopen\u001b[38;5;241m.\u001b[39mmatch(rawdata, i): \u001b[38;5;66;03m# < + letter\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m         k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_starttag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m startswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</\u001b[39m\u001b[38;5;124m\"\u001b[39m, i):\n\u001b[1;32m    172\u001b[0m         k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_endtag(i)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/html/parser.py:344\u001b[0m, in \u001b[0;36mHTMLParser.parse_starttag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_startendtag(tag, attrs)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_starttag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCDATA_CONTENT_ELEMENTS:\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_cdata_mode(tag)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/bs4/builder/_htmlparser.py:154\u001b[0m, in \u001b[0;36mBeautifulSoupHTMLParser.handle_starttag\u001b[0;34m(self, name, attrs, handle_empty_element)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m#print(\"START\", name)\u001b[39;00m\n\u001b[1;32m    153\u001b[0m sourceline, sourcepos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetpos()\n\u001b[0;32m--> 154\u001b[0m tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_starttag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msourceline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msourceline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43msourcepos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msourcepos\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;129;01mand\u001b[39;00m tag\u001b[38;5;241m.\u001b[39mis_empty_element \u001b[38;5;129;01mand\u001b[39;00m handle_empty_element:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# Unlike other parsers, html.parser doesn't send separate end tag\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# events for empty-element tags. (It's handled in\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# don't want handle_endtag() to cross off any previous end\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# events for tags of this name.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_endtag(name, check_already_closed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/bs4/__init__.py:721\u001b[0m, in \u001b[0;36mBeautifulSoup.handle_starttag\u001b[0;34m(self, name, namespace, nsprefix, attrs, sourceline, sourcepos, namespaces)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtagStack) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    718\u001b[0m          \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only\u001b[38;5;241m.\u001b[39msearch_tag(name, attrs))):\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melement_classes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTag\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnsprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrentTag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_most_recent_element\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43msourceline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msourceline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msourcepos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msourcepos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespaces\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#find all games with a specific supply card set and specified number of players\n",
    "no_required_players = 2\n",
    "tgt_supply = ['Cellar','Market','Militia','Mine','Moat','Remodel','Smithy','Village','Woodcutter','Workshop']\n",
    "\n",
    "#store filenames of logs with the correct supply card set\n",
    "filename_list = []\n",
    "\n",
    "#counter for number of files that could and couldn't be processed\n",
    "failures = 0\n",
    "successes = 0\n",
    "directories_processed = 0\n",
    "\n",
    "total_start_time = time.time()\n",
    "\n",
    "for tar_day_file in sorted(os.listdir(dir_name)):\n",
    "#tar_day_file = '20101213.tar.bz2'\n",
    "#longest_file_processing_time = 0\n",
    "#if True:\n",
    "    #time how long it takes to process directory\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #extract tar file to directory\n",
    "    if tar_day_file[-7:] == 'tar.bz2': \n",
    "        logging.debug(\"Extracting \" + dir_name  + tar_day_file)\n",
    "        with tarfile.open(dir_name + tar_day_file, 'r') as tar:\n",
    "            extract_path = dir_name + tar_day_file[:-8]\n",
    "            tar.extractall(extract_path)\n",
    "\n",
    "        #then loop through individual games\n",
    "        for game_log in os.listdir(extract_path):\n",
    "            #read and parse html\n",
    "            filename = extract_path + '/' + game_log\n",
    "            file = open(filename, mode = 'r')\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "            #convert html contents into a list of tabs, navigable strings etc\n",
    "            pre_tag = soup.find('pre')\n",
    "                                \n",
    "            #check that the file isnt empty\n",
    "            if pre_tag == None:\n",
    "                failures +=1 \n",
    "            else:\n",
    "                #check that game wasn't aborted\n",
    "                aborted = check_aborted_game(pre_tag.contents)\n",
    "\n",
    "                if aborted == True:\n",
    "                    failures +=1\n",
    "                else:\n",
    "                    #get player names and scores                      \n",
    "                    #player_list = get_players(soup)\n",
    "                    list_b_tags = soup.find_all('b'); \n",
    "                    no_players = len(list_b_tags)-1\n",
    "\n",
    "                    #for now we focus only on games with a set number of players\n",
    "                    if no_players == no_required_players:\n",
    "                        #get cards in supply                       \n",
    "                        supply_cards = get_supply_cards_with_no_of_players(no_players, pre_tag.contents)\n",
    "                        \n",
    "                        if supply_cards == tgt_supply:    \n",
    "                            filename_list.append(filename)\n",
    "                            print(filename)\n",
    "\n",
    "        #delete extracted directory and output timings\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(\"Processed directory \" + str(tar_day_file) + f\" in {elapsed_time/60} minutes\")\n",
    "        shutil.rmtree(extract_path)\n",
    "        directories_processed +=1\n",
    "        print(\"Number of directories processed \" + str(directories_processed))\n",
    "\n",
    "print(\"Directories processed: \" + str(directories_processed))\n",
    "print(\"Successes: \" + str(successes))\n",
    "print(\"Failures: \" + str(failures))  \n",
    "\n",
    "#write filename list to file\n",
    "output_filename = 'files_with_tgt_supply_' + str(no_required_players) + 'players.txt'\n",
    "with open(output_filename, 'w') as file:\n",
    "    file.write(','.join(filename_list) + '\\n')\n",
    "\n",
    "# Calculate the elapsed time\n",
    "total_end_time = time.time()\n",
    "elapsed_time = total_end_time - total_start_time\n",
    "\n",
    "print(f\"Total elapsed time: {elapsed_time/60} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f720939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to determine number of players\n",
    "def get_players(html_soup):\n",
    "    #look for entries of the form #n <name>: x points' where n is a positive integer - these are tagged with a 'b'\n",
    "    #in earlier log files the '#n' is dropped and hence we also need to consider this case\n",
    "    player_list = []\n",
    "    list_b_tags = html_soup.find_all('b'); \n",
    "    for tag in list_b_tags:\n",
    "        s = tag.text\n",
    "        #extract name (assume string of the form '#n ' comes before the name)\n",
    "        match = re.search(r'#\\d+ ', s)\n",
    "        if match != None:\n",
    "            #we need to find the right most ':' (some names may contain a ':')\n",
    "            colon_index = s.rfind(':')\n",
    "            if colon_index == -1:\n",
    "                player = s[match.end():] #sometimes the colon is in the next sibling\n",
    "            else:\n",
    "                player = s[match.end():colon_index]\n",
    "                player_list.append(player)\n",
    "            \n",
    "    #deal with second case where name is not preceeded by a '#n ', in this case we need to look for a ': n points'\n",
    "    if len(player_scores) == 0:\n",
    "        for tag in list_b_tags:\n",
    "            s = tag.text\n",
    "            match = re.search(r': (-?\\d+) point', s) #we drop the s at the end of points to deal with the case where someone scores 1\n",
    "            if match != None:\n",
    "                #in this case the name is contained in the text preceeded by a ':'\n",
    "                colon_position = match.start()\n",
    "                if colon_position == 0:\n",
    "                    #sometime the name is in the previous tag\n",
    "                    pdb.set_trace()\n",
    "                    player = s.prev_sibling.text\n",
    "                else:\n",
    "                    player = s[:colon_position]\n",
    "                player_list.append(player)\n",
    "                \n",
    "    return player_list\n",
    "    \n",
    "\n",
    "#function to log and catalogue a supply card set \n",
    "def log_supply_set(cards, filename, supply_cards_key, supply_cards_counter, supply_cards_filenames):\n",
    "    #first identify if we have seen this card set previously\n",
    "    \n",
    "    #NOTE: we make a scary assumption here that the player logs always have cards listed in the same order\n",
    "    #to be tested empirically. This is done to make the ocdde execute in a resaonable time frame\n",
    "    #sorted_cards = sorted(cards)\n",
    "    sorted_cards = cards\n",
    "    \n",
    "    previously_seen = False\n",
    "    \n",
    "    for index in supply_cards_key.keys():\n",
    "        if sorted_cards == supply_cards_key[index]:\n",
    "            #seen this set before, so increment supply cards counter and store the filename\n",
    "            supply_cards_counter[index] += 1\n",
    "            supply_cards_filenames[index].append(filename)\n",
    "            previously_seen = True\n",
    "            break\n",
    "    \n",
    "    if previously_seen == False:\n",
    "        #in this case we need to create a new entry in the relevant dictionaries\n",
    "        \n",
    "        #no of unique sets seen so far\n",
    "        index = len(supply_cards_key) + 1\n",
    "        supply_cards_key[index] = sorted_cards\n",
    "        supply_cards_counter[index] = 1\n",
    "        supply_cards_filenames[index] = [filename]\n",
    "    \n",
    "    return None\n",
    "\n",
    "def check_aborted_game(html_contents):\n",
    "    for (k,r) in enumerate(html_contents):\n",
    "        if ('game aborted' in r.text) or ('resigned' in r.text):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "#following function parses a single line which consists of number of cards (unless equal to one) and card types\n",
    "#each separated by a colon and ended with a full stop or a horizontal dashed line. It returns a list of cards \n",
    "#with card names duplicated according to the number of them in the row. Also the index of the full stop or \n",
    "#dashed line will be returned\n",
    "def parse_row_into_cards(html_contents):\n",
    "    card_list = []\n",
    "    for (k,r) in enumerate(html_contents):\n",
    "        #Need to be careful that the first content item doesn't contain a '....', causing \n",
    "        #the code to pickup a full stop\n",
    "        if ((('.' not in r) or (k == 0)) and r.name == None and ('----------------------' not in r)):\n",
    "            #check to see if trashing text contains the number of cards trashed\n",
    "            #number is contained in last two digits of text\n",
    "            try:\n",
    "                no_cards = int(r[-2:])\n",
    "            except ValueError:\n",
    "                no_cards = 1\n",
    "            #take next entry along which should be the card name\n",
    "            card_type = r.next_sibling.text\n",
    "            #and add copies of that to the dictionary\n",
    "            for count in range(0,no_cards):\n",
    "                card_list.append(card_type)\n",
    "        elif (('.' in r) or ('----------------------' in r)) and (k != 0):\n",
    "            return (k, card_list)\n",
    "\n",
    "#function to get players and scores\n",
    "def players_and_scores(html_soup):\n",
    "    #look for entries of the form #n <name>: x points' where n is a positive integer - these are tagged with a 'b'\n",
    "    #in earlier log files the '#n' is dropped and hence we also need to consider this case\n",
    "    player_scores = {}\n",
    "    list_b_tags = html_soup.find_all('b'); \n",
    "    for tag in list_b_tags:\n",
    "        s = tag.text\n",
    "        #extract name (assume string of the form '#n ' comes before the name)\n",
    "        match = re.search(r'#\\d+ ', s)\n",
    "        if match != None:\n",
    "            #we need to find the right most ':' (some names may contain a ':')\n",
    "            colon_index = s.rfind(':')\n",
    "            if colon_index == -1:\n",
    "                player = s[match.end():] #sometimes the colon is in the next sibling\n",
    "            else:\n",
    "                player = s[match.end():colon_index]\n",
    "            #next sibing contains the score, assume score is after a string of the form ': ' and is 2 digits long\n",
    "            score_text = tag.next_sibling\n",
    "            score = int(re.search(r'-?\\d+', score_text[2:5]).group()) \n",
    "            player_scores[player] = score\n",
    "            \n",
    "    #deal with second case where name is not preceeded by a '#n ', in this case we need to look for a ': n points'\n",
    "    if len(player_scores) == 0:\n",
    "        for tag in list_b_tags:\n",
    "            s = tag.text\n",
    "            match = re.search(r': (-?\\d+) point', s) #we drop the s at the end of points to deal with the case where someone scores 1\n",
    "            if match != None:\n",
    "                #in this case the name is contained in the text preceeded by a ':'\n",
    "                colon_position = match.start()\n",
    "                if colon_position == 0:\n",
    "                    #sometime the name is in the previous tag\n",
    "                    pdb.set_trace()\n",
    "                    player = s.prev_sibling.text\n",
    "                else:\n",
    "                    player = s[:colon_position]\n",
    "                score = int(re.search(r'-?\\d+', s[colon_position+1 : colon_position+4]).group()) \n",
    "                player_scores[player] = score\n",
    "                \n",
    "    return player_scores\n",
    "\n",
    "#extract number of turns for this game for each player\n",
    "def turns_for_each_player(player_list, html_contents):\n",
    "    total_turns = []\n",
    "    count = 0\n",
    "    for (k,r) in enumerate(html_contents):\n",
    "        if 'turns' in r.text:\n",
    "            turn_position = r.text.index('turns')\n",
    "            #assume number of turns is given by two digits and there is a space to the start of the word 'turn'q\n",
    "            total_turns.append(int(re.search(r'\\d+', r.text[turn_position-3:turn_position]).group()))\n",
    "            count += 1\n",
    "            if count == len(player_list):\n",
    "                break\n",
    "            \n",
    "    #note, turns are in same order as player names in html file\n",
    "    turns_by_player = {}\n",
    "    count = 0\n",
    "    for player in player_list:\n",
    "        turns_by_player[player] = total_turns[count]\n",
    "        count += 1\n",
    "    \n",
    "    return turns_by_player\n",
    "\n",
    "def get_supply_cards_with_no_of_players(no_of_players, html_contents):\n",
    "    #so we need to be careful figuring out the cards in the supply, first we scan down the file\n",
    "    # to see if there is a 'chosen cards are' string followed by ''<player name> vetoes'. In this\n",
    "    #case the players are making choices over the card supply, if this isnt present then the\n",
    "    #supply cards are given at the top of the file post a string that says 'cards in supply'\n",
    "\n",
    "    #start with the case where players can veto\n",
    "    vetoes_used = False\n",
    "    for (i,s) in enumerate(html_contents):\n",
    "        if 'chosen cards are' in s:\n",
    "            #loop over chosen supply cards\n",
    "            (index, cards) = parse_row_into_cards(html_contents[i:])\n",
    "            index_end = i + index \n",
    "            supply_cards = cards\n",
    "            vetoes_used = True\n",
    "            break\n",
    "    \n",
    "    if vetoes_used == True:\n",
    "        #next each player can veto a card\n",
    "        found_player_veto = 0\n",
    "        vetoed_cards = []\n",
    "        for s in html_contents[index_end:]:\n",
    "            if 'vetoes' in s:\n",
    "                vetoed_cards.append(s.next_sibling.text)\n",
    "                found_player_veto +=1\n",
    "                if (found_player_veto == no_of_players):\n",
    "                    break\n",
    "        #remove vetoed cards from list of supply cards\n",
    "        supply_cards = list(filter(lambda x: x not in vetoed_cards, supply_cards))\n",
    "            \n",
    "    #if this didnt occur move onto the second case\n",
    "    if vetoes_used == False:\n",
    "        for (i, s) in enumerate(html_contents):\n",
    "            if 'cards in supply' in s:\n",
    "                (index, cards) = parse_row_into_cards(html_contents[i:])\n",
    "                supply_cards = cards\n",
    "                break\n",
    "    \n",
    "    return supply_cards\n",
    "\n",
    "\n",
    "def get_supply_cards(players_list, html_contents):\n",
    "    #so we need to be careful figuring out the cards in the supply, first we scan down the file\n",
    "    # to see if there is a 'chosen cards are' string followed by ''<player name> vetoes'. In this\n",
    "    #case the players are making choices over the card supply, if this isnt present then the\n",
    "    #supply cards are given at the top of the file post a string that says 'cards in supply'\n",
    "\n",
    "    #start with the case where players can veto\n",
    "    vetoes_used = False\n",
    "    for (i,s) in enumerate(html_contents):\n",
    "        if 'chosen cards are' in s:\n",
    "            #loop over chosen supply cards\n",
    "            (index, cards) = parse_row_into_cards(html_contents[i:])\n",
    "            index_end = i + index \n",
    "            supply_cards = cards\n",
    "            vetoes_used = True\n",
    "            break\n",
    "    \n",
    "    if vetoes_used == True:\n",
    "        #next each player can veto a card\n",
    "        vetoed_cards = []\n",
    "        for player in players_list:\n",
    "            for s in html_contents[index_end:]:\n",
    "                check_string = player + ' vetoes'\n",
    "                if check_string in s:\n",
    "                    vetoed_cards.append(s.next_sibling.text)\n",
    "                    break\n",
    "        #remove vetoed cards from list of supply cards\n",
    "        supply_cards = list(filter(lambda x: x not in vetoed_cards, supply_cards))\n",
    "            \n",
    "    #if this didnt occur move onto the second case\n",
    "    if vetoes_used == False:\n",
    "        for (i, s) in enumerate(html_contents):\n",
    "            if 'cards in supply' in s:\n",
    "                (index, cards) = parse_row_into_cards(html_contents[i:])\n",
    "                supply_cards = cards\n",
    "                break\n",
    "    \n",
    "    return supply_cards\n",
    "\n",
    "def process_player_actions(player_list, turns_by_player, html_contents):\n",
    "    #use a dictionary of dictionaries to track gained cards by turn by player, and initialise keys\n",
    "    incremental_cards_by_turn = {}\n",
    "    for player in player_list:\n",
    "        incremental_cards_by_turn[player] = {}\n",
    "        for turn in range(1,turns_by_player[player]+1):\n",
    "            incremental_cards_by_turn[player][turn] = {}\n",
    "            incremental_cards_by_turn[player][turn] = {}\n",
    "            incremental_cards_by_turn[player][turn] = {}\n",
    "            incremental_cards_by_turn[player][turn] = {}\n",
    "        for turn in range(1,turns_by_player[player]+1):\n",
    "            incremental_cards_by_turn[player][turn]['buys'] = {}\n",
    "            incremental_cards_by_turn[player][turn]['trashing'] = {}\n",
    "            incremental_cards_by_turn[player][turn]['gaining'] = {}\n",
    "            incremental_cards_by_turn[player][turn]['trashes'] = {}\n",
    "        \n",
    "    for player in player_list:\n",
    "        turn_counter = 1\n",
    "        #string to check for a buy action\n",
    "        check_buy = player + ' buys'\n",
    "        #string to check if current player is trashing a card\n",
    "        check_trashing = 'trashing'\n",
    "        #string to check if current player is gaining a card\n",
    "        check_gaining = 'gaining'\n",
    "        #string to check if another player trashes a card. Howver, current player can both 'trashes' \n",
    "        #and 'trashing'. Also it is possible for a player to trash nothing\n",
    "        check_player_trashes = [x + ' trashes' for x in players] # need to check this!\n",
    "        #string to check if another player is gains a card (gains is used rather than\n",
    "        #gaining when a player gets a card out of turn)\n",
    "        check_player_gains = [ x + ' gains' for x in players]\n",
    "        #string to check end of turn\n",
    "        check_turn_end = '(' + player + ' draws:'\n",
    "        for (i,p) in enumerate(html_contents):\n",
    "            check_turn = player + '\\'s' + ' turn ' + str(turn_counter)\n",
    "            if check_turn in p:\n",
    "                buy_card_list = []\n",
    "                trashing_card_list = []\n",
    "                gaining_card_list = []\n",
    "                gains_card_list = {} #needs to be a dictionary as multiple players may gain in another player's round\n",
    "                trashes_card_list = {} #needs to be a dictionary as multiple players may need to trash in another player's round\n",
    "                for player_ in player_list:\n",
    "                    gains_card_list[player_] = [] \n",
    "                    trashes_card_list[player_] = [] \n",
    "                for (j,q) in enumerate(html_contents[i:]):\n",
    "                    player_gains_list = [ x in q for x in check_player_gains]\n",
    "                    player_trashes_list = [ x in q for x in check_player_trashes]\n",
    "                    if check_buy in q:\n",
    "                        (index, cards) = parse_row_into_cards(html_contents[i + j:])\n",
    "                        buy_card_list.append(cards)\n",
    "                    elif check_trashing in q:\n",
    "                        if 'trashing nothing' in r:\n",
    "                            break\n",
    "                        (index, cards) = parse_row_into_cards(html_contents[i + j:])\n",
    "                        trashing_card_list.append(cards)\n",
    "                    elif check_gaining in q:\n",
    "                        #also we need to check for a 'gaining nothing' case\n",
    "                        if 'gaining nothing' in r:\n",
    "                            break\n",
    "                        else:\n",
    "                            (index, cards) = parse_row_into_cards(html_contents[i + j:])\n",
    "                            gaining_card_list.append(cards)\n",
    "                    elif any(player_gains_list):\n",
    "                        #next we check if an opponent gains a card, e.g. a curse card\n",
    "                        #need to loop through opponents\n",
    "                        for (index, player_gains_check) in enumerate(player_gains_list):\n",
    "                            if player_gains_check == True:\n",
    "                                player_ = players[index]\n",
    "                                (index_, cards) = parse_row_into_cards(html_contents[i + j:])\n",
    "                                gains_card_list[player_].append(cards)\n",
    "                    elif any(player_trashes_list):\n",
    "                        #next we check if an opponent trashes a card\n",
    "                        for (index, player_trashes_check) in enumerate(player_trashes_list):\n",
    "                            if player_trashes_check == True:\n",
    "                                player_ = players[index]\n",
    "                                (index_, cards) = parse_row_into_cards(html_contents[i + j:])\n",
    "                                trashes_card_list[player_].append(cards)\n",
    "                    elif check_turn_end in q.text:\n",
    "                        incremental_cards_by_turn[player][turn_counter]['buys'] = buy_card_list\n",
    "                        incremental_cards_by_turn[player][turn_counter]['trashing'] = trashing_card_list\n",
    "                        incremental_cards_by_turn[player][turn_counter]['gaining'] = gaining_card_list\n",
    "                        for player_ in gains_card_list.keys():\n",
    "                            incremental_cards_by_turn[player_][turn_counter]['gains'] = gains_card_list[player_] \n",
    "                        for player_ in trashes_card_list.keys():\n",
    "                            incremental_cards_by_turn[player_][turn_counter]['trashes'] = trashes_card_list[player_] \n",
    "                        turn_counter += 1\n",
    "                        break\n",
    "    \n",
    "    #finally we flatten incremental_cards_by_turn into a dictionary of lists\n",
    "    for player in player_list:\n",
    "        for turns in range(1, turns_by_player[player]+1):\n",
    "            for cmd_type in incremental_cards_by_turn[player][turns].keys():\n",
    "                flattened_list = [item for sublist in incremental_cards_by_turn[player][turns][cmd_type] for item in sublist]\n",
    "                incremental_cards_by_turn[player][turns][cmd_type] = flattened_list\n",
    "    \n",
    "    return incremental_cards_by_turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f32de17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
